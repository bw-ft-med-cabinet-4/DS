{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"leaflyscrape.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+19bLKjAWcxvvgMG6l0CR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"GlVYr4_7Nlbj","colab_type":"code","outputId":"38269c04-93f4-49cc-a17a-cd0bb65548de","executionInfo":{"status":"ok","timestamp":1588111675949,"user_tz":420,"elapsed":12161,"user":{"displayName":"Cameron Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglyY273ODowizE78_HeYKHfwtYEYjSxjLvqea6Kw=s64","userId":"04205489972513259652"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!pip install pymongo[srv]\n","!pip install dnspython\n","!pip install requests\n","!pip install bs4\n","!pip install html2text\n","!pip install -U -q PyDrive\n","\n","import html2text\n","from ast import literal_eval\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","from pymongo import MongoClient\n","from bson.objectid import ObjectId\n","import numpy as np\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import drive\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user() #establish connection to a gdrive to write the eventual csv file to\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","gdrive = GoogleDrive(gauth)\n","\n","local_download_path = os.path.expanduser('~/data')\n","try:\n","  os.makedirs(local_download_path)\n","except: pass\n","\n","drive.mount('/content/drive/')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.6/dist-packages (3.10.1)\n","Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in /usr/local/lib/python3.6/dist-packages (from pymongo[srv]) (1.16.0)\n","Requirement already satisfied: dnspython in /usr/local/lib/python3.6/dist-packages (1.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.4.5.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n","Requirement already satisfied: html2text in /usr/local/lib/python3.6/dist-packages (2020.1.16)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YqdNO05amvrl","colab_type":"code","colab":{}},"source":["#136 seconds execution\n","\n","list_of_grid_page_URL = [] #generate the URLs for all the index pages listing weed strains\n","for i in range(113):\n","  list_of_grid_page_URL += ['https://www.leafly.com/strains?sort=name&page=' + str(i+2)]\n","\n","list_of_strains = []\n","for i in range(len(list_of_grid_page_URL)): #go to those pages and scrape the names of the strains\n","  result = requests.get(list_of_grid_page_URL[i])\n","  src = result.content\n","  soup = BeautifulSoup(src, 'lxml')\n","  links = soup.find_all('div', class_ = 'strain-tile__name')\n","  for i in range(len(links)):\n","    list_of_strains += [str(links[i])[31:-6]]\n","\n","for i in range(len(list_of_strains)): #clean up the names so they work as URLs\n","  list_of_strains[i] = list_of_strains[i].replace(' ', '-')\n","  list_of_strains[i] = list_of_strains[i].replace('.', '')\n","  list_of_strains[i] = list_of_strains[i].replace(\"'\", '')\n","  list_of_strains[i] = list_of_strains[i].lower()\n","\n","list_of_strain_URL = [] #turn the names into URLs that we can scrape\n","for i in range(len(list_of_strains)):\n","  list_of_strain_URL += ['https://www.leafly.com/strains/' + list_of_strains[i]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o08hWQYI0gto","colab_type":"code","colab":{}},"source":["parser = html2text.HTML2Text()\n","parser.ignore_links = True\n","client = MongoClient('mongodb+srv://test:test@medcabinet-if7ay.mongodb.net/test?retryWrites=true&w=majority')\n","db=client.get_database('app')\n","col = db['Strains']\n","\n","for i in range(752, len(list_of_strain_URL)): # for each strain's page on leafly\n","  result = requests.get(list_of_strain_URL[i]) #load the page\n","  src = result.content\n","  soup = BeautifulSoup(src, 'lxml')\n","  titles = soup.find_all('title')\n","\n","  if str(titles[0])[7:10] == '404': #check if its a 404\n","    print('404 ERROR: ', list_of_strain_URL[i])\n","    continue\n","  \n","  name = list_of_strains[i]\n","  print('Name: ', name)\n","  category = str(soup.find('h2', class_ = 'font-mono font-bold text-green text-xs '))[93:-9] #extract it's listed category Sativa/Indica/\n","  if len(category) == 0: #search for the other class name\n","    category = str(soup.find('h2', class_ = 'font-mono font-bold text-green text-xs pt-xl'))[98:-9]\n","    print('Category: ', category)\n","  else:\n","    print('Category: ', category)\n","\n","  avg_thc = str(soup.find('div', class_ = 'font-body'))[23:27].replace('<', '').replace('!','').strip() #store thc if it exists\n","  print('Avg THC: ', avg_thc)\n","  if avg_thc == 'pr-':\n","    agg_thc = ''\n","  try:\n","    agv_tch = float(avg_thc)\n","  except:\n","    print(\"no THC info\")\n","\n","  flavor_html = str(soup.findAll('div', class_ = 'flex flex-col')) #get terpine mix\n","  flavor_list = literal_eval(parser.handle(flavor_html).replace('\\n', 'j').replace('jj', \"'\")[:-1])\n","  print(\"Flavors: \", flavor_list)\n","\n","  energy_html = str(soup.findAll('div', class_ = 'calm-energize__mark bg-leafly-white absolute top-0 bottom-0')) #get energy value\n","  if len(energy_html) < 100:\n","    energy = '?'\n","  else:\n","    energy = literal_eval(energy_html[92:97])\n","  print('Energy: ', energy)\n","\n","  description_html = str(soup.findAll('div', class_ = 'md:mb-xxl strain__description relative overflow-hidden')) #get description\n","  description = parser.handle(description_html).replace('\\n','').replace('[', '').replace(']','')\n","  print(\"Description: \", description)\n","\n","  try:\n","    effect_html = str(soup.findAll('div', class_ = 'mb-xl relative w-full')) #get effect array and values\n","    effect_list = literal_eval(parser.handle(effect_html).replace('\\n','j').replace('jj',\"'\")[:-1])\n","    print('Effect List: ', effect_list)\n","    print('--------------------------------------')\n","  except:\n","    effect_list = []\n","    isStub = True\n","  positive_list = []\n","  positive_value_list = []\n","  negative_list = []\n","  negative_value_list = []\n","  treats_list = []\n","  treats_value_list = []\n","\n","  isStub = False\n","  \n","  if len(effect_list) < 15: #look at how much data we've got, if certain effect info was missing its a stub\n","      isStub = True\n","  else:\n","    for i in range(5):\n","      positive_list += [effect_list[i][:-3].strip()]\n","      positive_value_list += [int(effect_list[i][-3:].replace(' ', '').replace('%', ''))]\n","    for i in range(5, 10):\n","      treats_list += [effect_list[i][:-3].strip()]\n","      treats_value_list += [int(effect_list[i][-3:].replace(' ', '').replace('%', ''))]\n","    for i in range(10, len(effect_list)):\n","      negative_list += [effect_list[i][:-3].strip()]\n","      negative_value_list += [int(effect_list[i][-3:].replace(' ', '').replace('%', ''))]\n","\n","  new_record = { #write each entry to the database\n","  \"_id\": ObjectId(),\n","  \"name\": name,\n","  \"type\": category,\n","  \"avg_thc\": avg_thc,\n","  \"energy\": energy,\n","  \"flavor\": flavor_list,\n","  \n","  \"positive effect\": positive_list,\n","  \n","  \"positive effect value\": positive_value_list,\n","  \"negative effect\": negative_list,\n","  \"negative effect value\": negative_value_list,\n","  \"treats\": treats_list,\n","  \"treats value\": treats_value_list,\n","  \"Description\": description,\n","  \"isStub\": isStub\n","  }\n","  \n","  col.insert_one(new_record)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3TKLwndh5Dc","colab_type":"code","outputId":"22a273cb-c387-4715-fad2-6a0c2180f815","executionInfo":{"status":"ok","timestamp":1588278015754,"user_tz":420,"elapsed":173225,"user":{"displayName":"Cameron Ken","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglyY273ODowizE78_HeYKHfwtYEYjSxjLvqea6Kw=s64","userId":"04205489972513259652"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["client = MongoClient('mongodb+srv://test:test@medcabinet-if7ay.mongodb.net/test?retryWrites=true&w=majority')\n","db=client.get_database('app')\n","col = db['Strains']\n","results = col.find({'isStub':False}) #find all high information entries\n","\n","\n","list_of_names = [] #create lists to turn into series\n","list_of_energy = []\n","list_of_flavor = []\n","list_of_negative = []\n","list_of_positive = []\n","list_of_negative_v = []\n","list_of_positive_v = []\n","list_of_treats = []\n","list_of_treats_v = []\n","list_of_types = []\n","list_of_thc = []\n","\n","for i in range(results.count()):\n","  list_of_energy += [results[i]['energy']] #collect each value into a list\n","  list_of_flavor += [results[i]['flavor']]\n","  list_of_names += [results[i]['name']]\n","  list_of_negative += [results[i]['negative effect']]\n","  list_of_negative_v += [results[i]['negative effect value']]\n","  list_of_positive += [results[i]['positive effect']]\n","  list_of_positive_v += [results[i]['positive effect value']]\n","  list_of_treats += [results[i]['treats']]\n","  list_of_treats_v += [results[i]['treats value']]\n","  list_of_types += [results[i]['type']]\n","  try: \n","    list_of_thc += [float(results[i]['avg_thc'])]\n","  except:\n","    list_of_thc += [np.nan]\n","  \n","leafly_strains = pd.DataFrame() #white each list to a series compile to a dataframe\n","leafly_strains['name'] = pd.Series(list_of_names)\n","leafly_strains['type'] = pd.Series(list_of_types)\n","leafly_strains['treats'] = pd.Series(list_of_treats)\n","leafly_strains['treats_value'] = pd.Series(list_of_treats_v)\n","leafly_strains['positive_effect'] = pd.Series(list_of_positive)\n","leafly_strains['positive_effect_value'] = pd.Series(list_of_positive_v)\n","leafly_strains['negative_effect'] = pd.Series(list_of_negative)\n","leafly_strains['negative_effect_value'] = pd.Series(list_of_negative_v)\n","leafly_strains['flavors'] = pd.Series(list_of_flavor)\n","leafly_strains['energy'] = pd.Series(list_of_energy)\n","leafly_strains['avg_thc'] = pd.Series(list_of_thc)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n","  del sys.path[0]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IJIqrJILlNbl","colab":{}},"source":["leafly_strains.to_csv('leafly_strains.csv') #write to file\n","!cp leafly_strains.csv \"drive/My Drive/\""],"execution_count":0,"outputs":[]}]}